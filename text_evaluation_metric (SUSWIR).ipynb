{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2d01fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#import Levenshtein\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.metrics import jaccard_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a63df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59cc9db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab5c2ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f1a785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models import Word2Vec\n",
    "#from sklearn.metrics.pairwise import euclidean_distances\n",
    "#from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a722c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to download NLTK resources\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('maxent_ne_chunker')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('words')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "032ab4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "840de8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.meteor_score import meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2bd7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(r'C:\\Users\\Abdullah\\Text_Evaluation_Metrics\\dataset\\test.csv',sep = ',')\n",
    "#data = pd.read_csv(r'C:\\Users\\Abdullah\\Text_Evaluation_Metrics\\dataset\\billsum\\ustest_processed.csv',sep = ',')\n",
    "#data = pd.read_csv(r'C:\\Users\\Abdullah\\Text_Evaluation_Metrics\\dataset\\bbc_news\\BBCarticles_csv.csv',sep = ',',encoding='latin-1')\n",
    "#data = pd.read_csv(r'C:\\Users\\Abdullah\\Text_Evaluation_Metrics\\dataset\\Samsum\\samsum-test.csv',sep = ',')\n",
    "#data = pd.read_csv(r'C:\\Users\\Abdullah\\Text_Evaluation_Metrics\\dataset\\dialog_sum\\CSV\\test.csv',sep = ',')\n",
    "### machine learning model ######\n",
    "data = pd.read_csv(r'C:\\Users\\Abdullah\\Text_Evaluation_Metrics\\dataset\\t5_bbc\\t5_bbc_test.csv',sep = ',',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfb8454f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Article</th>\n",
       "      <th>original_Summary</th>\n",
       "      <th>Predicted_Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% t...</td>\n",
       "      <td>revenues rose 6.4% to $42.09bn. TimeWarner pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "      <td>at $1.2871 against the euro, from $1.2974 on T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Ro...</td>\n",
       "      <td>owners of embattled Russian oil giant to ask b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the ...</td>\n",
       "      <td>it made a pre-tax profit of Â£75m ($141m) comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>Pernod has reduced the debt it took on to fund...</td>\n",
       "      <td>Ricard. Allied Domecq shares in London rose 4%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            Article  \\\n",
       "0           0  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
       "1           1  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
       "2           2  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
       "3           3  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
       "4           4  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
       "\n",
       "                                    original_Summary  \\\n",
       "0  TimeWarner said fourth quarter sales rose 2% t...   \n",
       "1  The dollar has hit its highest level against t...   \n",
       "2  Yukos' owner Menatep Group says it will ask Ro...   \n",
       "3  Rod Eddington, BA's chief executive, said the ...   \n",
       "4  Pernod has reduced the debt it took on to fund...   \n",
       "\n",
       "                                   Predicted_Summary  \n",
       "0  revenues rose 6.4% to $42.09bn. TimeWarner pos...  \n",
       "1  at $1.2871 against the euro, from $1.2974 on T...  \n",
       "2  owners of embattled Russian oil giant to ask b...  \n",
       "3  it made a pre-tax profit of Â£75m ($141m) comp...  \n",
       "4  Ricard. Allied Domecq shares in London rose 4%...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78c28d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_column_names = {'clean_text': 'article', 'summary': 'highlights'} # billsum\n",
    "#new_column_names = {'Text': 'article', 'Summary': 'highlights'} # bbc\n",
    "#new_column_names = {'dialogue': 'article', 'summary': 'highlights'} # samsum\n",
    "#new_column_names = {'dialogue': 'article', 'summary': 'highlights'} # dialog sum\n",
    "#new_column_names = {'inputs': 'article', 'inferences': 'highlights'} # dialog sum\n",
    "### machine learning model\n",
    "new_column_names = {'Article': 'article', 'Predicted_Summary': 'highlights'} # t5 bbc \n",
    "data.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a96830c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b1babecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>article</th>\n",
       "      <th>original_Summary</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% t...</td>\n",
       "      <td>revenues rose 6.4% to $42.09bn. TimeWarner pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "      <td>at $1.2871 against the euro, from $1.2974 on T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Ro...</td>\n",
       "      <td>owners of embattled Russian oil giant to ask b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the ...</td>\n",
       "      <td>it made a pre-tax profit of Â£75m ($141m) comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>Pernod has reduced the debt it took on to fund...</td>\n",
       "      <td>Ricard. Allied Domecq shares in London rose 4%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            article  \\\n",
       "0           0  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
       "1           1  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
       "2           2  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
       "3           3  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
       "4           4  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
       "\n",
       "                                    original_Summary  \\\n",
       "0  TimeWarner said fourth quarter sales rose 2% t...   \n",
       "1  The dollar has hit its highest level against t...   \n",
       "2  Yukos' owner Menatep Group says it will ask Ro...   \n",
       "3  Rod Eddington, BA's chief executive, said the ...   \n",
       "4  Pernod has reduced the debt it took on to fund...   \n",
       "\n",
       "                                          highlights  \n",
       "0  revenues rose 6.4% to $42.09bn. TimeWarner pos...  \n",
       "1  at $1.2871 against the euro, from $1.2974 on T...  \n",
       "2  owners of embattled Russian oil giant to ask b...  \n",
       "3  it made a pre-tax profit of Â£75m ($141m) comp...  \n",
       "4  Ricard. Allied Domecq shares in London rose 4%...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ceb2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#article_values = data['article'].tolist()\n",
    "article_values = data['original_Summary'].tolist()\n",
    "summary_values = data['highlights'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "adf1d040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values from column 'article': 2225\n",
      "Values from column 'highlights': 2225\n"
     ]
    }
   ],
   "source": [
    "# Print the extracted lists\n",
    "print(\"Values from column 'article':\", len(article_values))\n",
    "print(\"Values from column 'highlights':\", len(summary_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66d4d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for data cleaning\n",
    "def clean_text(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word.lower() not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # Apply stemming\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Rejoin the cleaned words into a single string\n",
    "    cleaned_text = \" \".join(words)\n",
    "    cleaned_text = cleaned_text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cdfecf",
   "metadata": {},
   "source": [
    "## Parameter and Methods \n",
    "\n",
    "### 1.Coherence and Cohesion : LSA+Cosine Similarity \n",
    "### 2.Relevance : METEOR \n",
    "### 3.Redundancy : Cosine Similarity (only on summary text)\n",
    "### 4.Bias Avoidance : NER + Jaccard Similarity \n",
    "### 5.Conciseness : LDA + Jaccard Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dae24240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(original_content, summary):\n",
    "    # Apply data cleaning to the original content and summary\n",
    "    cleaned_original_content = clean_text(original_content)\n",
    "    cleaned_summary = clean_text(summary)\n",
    "    #cleaned_human_summary = clean_text(summary)\n",
    "    #print('cleaned_original_content',cleaned_original_content)\n",
    "    #print('\\n')\n",
    "    #print('cleaned_summary',cleaned_summary)\n",
    "    #print('\\n')\n",
    "    \n",
    "    # Factor weights (can be adjusted based on importance)\n",
    "    factor_weights = {\n",
    "        'Semantic Similarity': 0.25,\n",
    "        'Relevance': 0.25,\n",
    "        #'Coherence and Cohesion': 0.30,\n",
    "        'Redundancy': 0.25,\n",
    "        'Bias Avoidance': 0.25\n",
    "        #'Conciseness': 0.25\n",
    "    }\n",
    "    # Factor scores (on a scale from 0 to 100)\n",
    "    factor_scores = {}\n",
    "    \n",
    "    # Factor: Semantic Similarity\n",
    "    # (Use Latent Semantic Analysis (LSA) + CS)\n",
    "    \n",
    "    lsa_score = semantic_similarity_score(original_content, summary)\n",
    "    factor_scores['Semantic Similarity'] = 100 * lsa_score\n",
    "    \n",
    "    # Factor: Relevance\n",
    "    #Method used : METEOR\n",
    "    relevance_score = relevance_similarity(original_content, summary)\n",
    "    factor_scores['Relevance'] = 100 * relevance_score\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Factor: Redundancy\n",
    "    # Calculate redundancy using cosine similarity between summary sentences (CS)\n",
    "    redundancy_score = redundancy_analysis(summary)\n",
    "    factor_scores['Redundancy'] = 100 * redundancy_score\n",
    "     \n",
    "    \n",
    "    # Factor: Bias Avoidance\n",
    "    # (Use Named Entity Recognition + JS)\n",
    "    bias_avoidance_score = bias_avoidance_analysis(original_content, summary)\n",
    "    factor_scores['Bias Avoidance'] = 100 * bias_avoidance_score\n",
    "    \n",
    "    # Calculate overall score as weighted sum of factor scores\n",
    "    overall_score = sum(factor_scores[factor] * factor_weights[factor] for factor in factor_weights)/100\n",
    "    return overall_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "718c8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_score(original_contents, summaries):\n",
    "    total_score = 0\n",
    "    for original_content, summary in zip(original_contents, summaries):\n",
    "        score = calculate_score(original_content, summary)\n",
    "        ##print('Score: ',score)\n",
    "        total_score += score\n",
    "    average_score = total_score / len(original_contents)\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71d33815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cosine_similarity_score_for_redundancy(vector1, vector2):\n",
    "    similarity = cosine_similarity(vector1, vector2)[0][0]\n",
    "    return similarity\n",
    "\n",
    "# Perform Latent Semantic Analysis (LSA) on the original content and summary\n",
    "# this function calculates the cosine similarity between two vectors. The vectors vector1 and vector2 are reshaped to ensure\n",
    "#that they have the same shape before computing the cosine similarity.    \n",
    "def calculate_cosine_similarity(vector1, vector2):\n",
    "    similarity = cosine_similarity(vector1.reshape(1, -1), vector2.reshape(1, -1))\n",
    "    return similarity[0][0]\n",
    "\n",
    "def semantic_similarity_score(original_content, summary):\n",
    "    # Perform Latent Semantic Analysis (LSA) on the original content and summary\n",
    "    documents = [original_content, summary]\n",
    "\n",
    "    # Create a document-term matrix using TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(documents)\n",
    "\n",
    "    # Apply LSA for dimensionality reduction\n",
    "    num_topics = 2  # Number of topics (latent dimensions)\n",
    "    lsa = TruncatedSVD(n_components=num_topics)\n",
    "    X_lsa = lsa.fit_transform(X)\n",
    "\n",
    "    # Calculate cosine similarity between the original text and its summary\n",
    "    cosine_similarity_score = calculate_cosine_similarity(X_lsa[0], X_lsa[1])\n",
    "\n",
    "    ###print(\"Cosine Similarity Score (LSA) for Coherence and Cohesion:\", cosine_similarity_score)\n",
    "    lsa_sim = cosine_similarity_score\n",
    "    return lsa_sim\n",
    "\n",
    "\n",
    "def relevance_similarity(original_content, summary):\n",
    "    # Implement METEOR to evaluate the relevance of the summary to the original content\n",
    "    ### higher score is better ####\n",
    "    main_text =  word_tokenize(original_content)\n",
    "    summary =  word_tokenize(summary)\n",
    "\n",
    "    # Calculate METEOR score\n",
    "    meteor = meteor_score([main_text], summary)\n",
    "    ###print(\"relevance_similarity (meteor):\", meteor)\n",
    "    return meteor\n",
    "\n",
    "def redundancy_analysis(summary):\n",
    "    sentences = sent_tokenize(summary)\n",
    "    # Handle the case of a single sentence summary\n",
    "    if len(sentences) == 1:\n",
    "        return 1.0\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(sentences)\n",
    "    \n",
    "    similarity_threshold = 0.5\n",
    "    redundant_count = 0\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        ##print('base sentences: ', sentences[i])\n",
    "        for j in range(i + 1, len(sentences)):\n",
    "            ##print('com sentences: ', sentences[j])\n",
    "            similarity_score = cosine_similarity_score_for_redundancy(vectors[i], vectors[j])\n",
    "            ##print('similarity_score:',similarity_score)\n",
    "            if similarity_score < similarity_threshold:\n",
    "                redundant_count += 1\n",
    "        ##print('......................................')\n",
    "    # Calculate redundancy score as a ratio of redundant pairs to total pairs\n",
    "    total_pairs = (len(sentences) * (len(sentences) - 1)) / 2\n",
    "    ##print('redundant_count: ',redundant_count)\n",
    "    ##print('total_pairs: ',total_pairs)\n",
    "    ##redundancy_score = 1 - (redundant_count / total_pairs)\n",
    "    redundancy_score = (redundant_count / total_pairs)\n",
    "    ###print(\"redundancy_analysis (cosine similarity)\", redundancy_score)\n",
    "    return redundancy_score\n",
    "    \n",
    "\n",
    "def bias_avoidance_analysis(original_content, summary):\n",
    "    # Use Named Entity Recognition (NER) to identify named entities in the summary\n",
    "    ### higher score is better ###\n",
    "    original_entities = extract_named_entities(original_content)\n",
    "    ##print('-------------------------------------------------------')\n",
    "    ##print('original_entities: ',original_entities)\n",
    "    summary_entities = extract_named_entities(summary)\n",
    "    ##print('-------------------------------------------------------')\n",
    "    ##print('summary_entities: ',summary_entities)\n",
    "    \n",
    "    # Calculate the Jaccard similarity of named entities to measure bias avoidance\n",
    "    jaccard_score = calculate_jaccard_similarity(original_entities, summary_entities)\n",
    "    ###print(\"bias_avoidance_analysis (NER)\", jaccard_score)\n",
    "    return jaccard_score\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    entities = []\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        pos_tags = nltk.pos_tag(words)\n",
    "        chunked = ne_chunk(pos_tags)\n",
    "        for subtree in chunked:\n",
    "            if isinstance(subtree, nltk.Tree):\n",
    "                entity = \" \".join([word for word, tag in subtree.leaves()])\n",
    "                entities.append(entity)\n",
    "    return set(entities)\n",
    "\n",
    "def calculate_jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1) + len(set2) - intersection\n",
    "    jaccard_similarity = intersection / union if union > 0 else 0\n",
    "    return jaccard_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff96cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3857585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_content = 'A big brown fox jump over the lazy dog. The dog is small in size'\n",
    "#summary = 'A large brown fox leaped across the lethargic dog. The canine is of a diminutive stature.'\n",
    "\n",
    "#original_content = 'Munich is one of the biggest city in Germany. It has a football club '\n",
    "#summary = 'Bayern Munich is a socker club in Germany. It is a famous club'\n",
    "\n",
    "\n",
    "#######abstractive summary #############\n",
    "original_content ='''\n",
    "The concept of artificial intelligence (AI) has evolved dramatically over the past few decades. AI, initially thought to be confined to science fiction, is now an integral part of our daily lives. This transformation is largely due to the exponential growth in computing power and the development of sophisticated algorithms.\n",
    "\n",
    "In the early days of AI, the focus was on rule-based systems, where programmers explicitly defined the rules for the computer to follow. These systems had limited capabilities and struggled with complex, real-world problems. However, as computing power increased, machine learning techniques emerged.\n",
    "\n",
    "Machine learning allows AI systems to learn from data and make predictions or decisions without being explicitly programmed. This shift has led to remarkable advances in areas such as natural language processing, computer vision, and recommendation systems. AI-powered applications are now commonplace, from virtual personal assistants like Siri to autonomous vehicles.\n",
    "\n",
    "One of the most exciting AI developments is deep learning, a subset of machine learning that involves neural networks inspired by the human brain. Deep learning models, particularly convolutional neural networks (CNNs) and recurrent neural networks (RNNs), have achieved groundbreaking results in image and speech recognition, language translation, and more. They can process massive datasets and extract intricate patterns, leading to remarkable accuracy.\n",
    "\n",
    "The impact of AI is felt across industries, including healthcare, finance, and manufacturing. In healthcare, AI is used for disease diagnosis, drug discovery, and personalized treatment plans. Financial institutions rely on AI for fraud detection, algorithmic trading, and customer service chatbots. Manufacturers employ AI-powered robotics and automation for increased efficiency and quality control.\n",
    "\n",
    "Despite its transformative potential, AI also raises ethical and societal concerns. The collection and use of personal data, algorithmic biases, and the potential for job displacement are among the challenges that must be addressed. Regulatory frameworks and ethical guidelines are being developed to ensure responsible AI development and deployment.\n",
    "\n",
    "Looking ahead, the future of AI holds promise and uncertainty. As AI systems become more capable and autonomous, questions about their decision-making processes and accountability become more pressing. Continued research, collaboration, and public discourse are essential to navigate the complex landscape of AI and ensure that it benefits society as a whole.\n",
    "'''\n",
    "\n",
    "summary = '''\n",
    "Artificial intelligence (AI) has undergone a profound evolution, moving from science fiction to everyday reality. This transformation is driven by increased computing power and the rise of machine learning, allowing AI systems to learn and make decisions autonomously. Deep learning, inspired by the human brain, has pushed the boundaries of AI, enabling breakthroughs in areas like language processing and image recognition.\n",
    "\n",
    "AI's impact spans industries, from healthcare and finance to manufacturing, revolutionizing processes and decision-making. However, ethical concerns, data privacy, and potential job displacement pose challenges. Regulatory efforts aim to ensure responsible AI development.\n",
    "\n",
    "The future of AI holds great promise but demands careful navigation of ethical and societal issues, making ongoing research and public dialogue crucial for harnessing AI's potential for the benefit of society.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b415687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Score: 0.5496\n"
     ]
    }
   ],
   "source": [
    "score = calculate_score(original_content, summary)\n",
    "print(f\"Overall Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50cb2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### summary does not match with context ###\n",
    "original_content = '''\n",
    "In the heart of the bustling city, there stood a magnificent cathedral, a testament to centuries of artistry and devotion. Its towering spires reached for the heavens, and its stained glass windows bathed the interior in a kaleidoscope of colors. Pilgrims and tourists alike marveled at its intricate architecture, a blend of Gothic and Renaissance styles.\n",
    "\n",
    "Inside, the cathedral was a sanctuary of serenity. Sunlight streamed through the windows, casting ethereal patterns on the stone floor. The echoes of whispered prayers filled the air, and the scent of incense lingered, a fragrant offering to the divine.\n",
    "\n",
    "Generations had contributed to this sacred place, from the master craftsmen who sculpted its façade to the faithful who tended its gardens. It was a living legacy, a symbol of both faith and human ingenuity.\n",
    "'''\n",
    "\n",
    "summary = '''\n",
    "Amidst the urban chaos, a hidden garden thrived, a living canvas of vibrant life. Its lush foliage sprawled, forming a lush tapestry of greens and reds, a testament to nature's artistry. Birds flitted in and out, their songs a colorful symphony.\n",
    "\n",
    "Within this haven, tranquility reigned. Sunlight dappled the earth, casting playful shadows. Laughter and music filled the air, a celebration of life's beauty, while the scent of blooming flowers enveloped all.\n",
    "\n",
    "Generations of caretakers nurtured this oasis, from the green-thumbed gardeners who tended its blooms to the children who played among its wonders. It was a living testament, a symbol of nature's resilience and human stewardship\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e57ed89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "original_entities:  {'Renaissance', 'Gothic', 'Sunlight', 'Inside'}\n",
      "-------------------------------------------------------\n",
      "summary_entities:  {'Sunlight'}\n",
      "Overall Score: 0.5396\n"
     ]
    }
   ],
   "source": [
    "score = calculate_score(original_content, summary)\n",
    "print(f\"Overall Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e73e8a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.4729\n"
     ]
    }
   ],
   "source": [
    "#score = calculate_score(original_content, summary)\n",
    "#print(f\"Overall Score: {score:.2f}\")\n",
    "average_score = calculate_average_score(article_values, summary_values)\n",
    "print(f\"Average Score: {average_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "468f024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########Average Score: 0.4896 (after cleaning)\n",
    "#0.4783 (3331)\n",
    "# 0.4276 (all same)\n",
    "\n",
    "#Average Score: 0.4824 (all same billsum)\n",
    "#Average Score: 0.6539 (all same bbc)\n",
    "#Average Score: 0.5108 (all same samsum)\n",
    "#Average Score: 0.4918 (all same dialog sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a5cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f64b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d033dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Score: 0.4667\n"
     ]
    }
   ],
   "source": [
    "#### Summary 1 (Real Abstractive Summary):\n",
    "original_content ='''\n",
    "Artificial intelligence (AI) has undergone a profound evolution, moving from science fiction to everyday reality. \n",
    "This transformation is driven by increased computing power and the rise of machine learning, allowing AI systems to \n",
    "learn and make decisions autonomously. Deep learning, inspired by the human brain, has pushed the boundaries of AI, \n",
    "enabling breakthroughs in areas like language processing and image recognition. AI's impact spans industries, \n",
    "from healthcare and finance to manufacturing, revolutionizing processes and decision-making. However, ethical concerns, \n",
    "data privacy, and potential job displacement pose challenges. Regulatory efforts aim to ensure responsible AI development. \n",
    "The future of AI holds great promise but demands careful navigation of ethical and societal issues, making ongoing research \n",
    "and public dialogue crucial for harnessing AI's potential for the benefit of society.\n",
    "'''\n",
    "\n",
    "summary = '''\n",
    "The evolution of artificial intelligence (AI) from science fiction to everyday reality has been driven by increased computing \n",
    "power, machine learning, and deep learning. AI has revolutionized multiple industries but raised concerns about ethics, data \n",
    "privacy, and job displacement. Ethical regulation is crucial for responsible AI development.\n",
    "'''\n",
    "score = calculate_score(original_content, summary)\n",
    "print(f\"Overall Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "542cbcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Score: 0.4716\n"
     ]
    }
   ],
   "source": [
    "#### Summary 2 (Non-Matching Summary): \n",
    "original_content ='''\n",
    "Artificial intelligence (AI) has undergone a profound evolution, moving from science fiction to everyday reality. \n",
    "This transformation is driven by increased computing power and the rise of machine learning, allowing AI systems to \n",
    "learn and make decisions autonomously. Deep learning, inspired by the human brain, has pushed the boundaries of AI, \n",
    "enabling breakthroughs in areas like language processing and image recognition. AI's impact spans industries, \n",
    "from healthcare and finance to manufacturing, revolutionizing processes and decision-making. However, ethical concerns, \n",
    "data privacy, and potential job displacement pose challenges. Regulatory efforts aim to ensure responsible AI development. \n",
    "The future of AI holds great promise but demands careful navigation of ethical and societal issues, making ongoing research \n",
    "and public dialogue crucial for harnessing AI's potential for the benefit of society.\n",
    "'''\n",
    "\n",
    "summary = '''\n",
    "The incredible rise of AI, like a phoenix from the ashes, has altered our world. As AI blossoms, \n",
    "we must cherish the seeds of responsibility, nurture them into robust trees of ethical practice, \n",
    "and keep them vibrant through a symphony of public discourse. In the end, AI is a canvas where the brushstrokes of \n",
    "society paint the future.\n",
    "'''\n",
    "score = calculate_score(original_content, summary)\n",
    "print(f\"Overall Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e19da941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Score: 0.3756\n"
     ]
    }
   ],
   "source": [
    "#original_content ='There is a brown fox. It is really quick. It jumped over the lazy dog. The dog is small in size.'\n",
    "original_content ='''\n",
    "In a serene landscape, a quick brown fox adds a burst of energy to the scene with its remarkable agility. Its luscious brown fur seamlessly blends with the natural surroundings as it gracefully leaps over a small, slumbering dog. Despite its compact size, the lazy dog remains undisturbed, embodying the essence of canine relaxation. This impromptu performance becomes a picturesque moment, where the fox's swift movements during the jump inject a burst of liveliness into the otherwise tranquil tableau of the lazy dog's repose.\n",
    "'''\n",
    "summary =  'The quick brown fox jumped over the lazy fox'\n",
    "score = calculate_score(original_content, summary)\n",
    "print(f\"Overall Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52cfcd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Score: 0.3046\n"
     ]
    }
   ],
   "source": [
    "#summary ='There is a brown fox. It is really quick. It jumped over the lazy dog. The dog is small in size.'\n",
    "original_content ='''\n",
    "In a serene landscape, a quick brown fox adds a burst of energy to the scene with its remarkable agility. Its luscious brown fur seamlessly blends with the natural surroundings as it gracefully leaps over a small, slumbering dog. Despite its compact size, the lazy dog remains undisturbed, embodying the essence of canine relaxation. This impromptu performance becomes a picturesque moment, where the fox's swift movements during the jump inject a burst of liveliness into the otherwise tranquil tableau of the lazy dog's repose.\n",
    "'''\n",
    "#original_content =  'The fast wood-coloured fox hopped over the lethargic dog'\n",
    "summary  = 'A nimble, wood-coloured fox swiftly leaped above the lethargic and petite dog.'\n",
    "score = calculate_score(original_content, summary)\n",
    "print(f\"Overall Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e7963f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc824f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef07150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff6e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
